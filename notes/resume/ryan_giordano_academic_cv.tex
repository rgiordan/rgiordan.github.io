\documentclass[margin,line]{res}

\usepackage[hidelinks]{hyperref}
\usepackage{xspace}
\usepackage{wasysym}
\usepackage{marvosym}

\oddsidemargin -.5in
\evensidemargin -.5in
\textwidth=6.0in
\itemsep=0in
\parsep=0in
\setlength{\pdfpagewidth}{\paperwidth}
\setlength{\pdfpageheight}{\paperheight}

\newenvironment{list1}{
  \begin{list}{\ding{113}}{%
      \setlength{\itemsep}{0in}
      \setlength{\parsep}{0in} \setlength{\parskip}{0in}
      \setlength{\topsep}{0in} \setlength{\partopsep}{0in}
      \setlength{\leftmargin}{0in}}}{\end{list}} % was 0.17in
\newenvironment{list2}{
  \begin{list}{$\bullet$}{%
      \setlength{\itemsep}{0in}
      \setlength{\parsep}{0in} \setlength{\parskip}{0in}
      \setlength{\topsep}{0in} \setlength{\partopsep}{0in}
      \setlength{\leftmargin}{0.2in}}}{\end{list}}

\newenvironment{talkgroup}{\setlength{\parskip}{3pt}\everypar{\hangafter=1\hangindent=1em\relax}\par}{\par\everypar{\hangafter=0\relax}}

\newif\ifpublic
\publicfalse
%\publictrue

\newcommand{\me}{\textbf{R.~J.~Giordano}\xspace}
\newcommand{\mestar}{\textbf{R.~J.~Giordano}$^{\star}$\xspace}
\newcommand{\trevor}{T.~C.~Campbell\xspace}
\newcommand{\trevorstar}{T.~C.~Campbell$^{\star}$\xspace}
\newcommand{\tamara}{T.~Broderick\xspace}
\newcommand{\liam}{L.~Paninski\xspace}
\newcommand{\vhw}{M.~Vilain, \me \& B.~Wellner\xspace}

\ifpublic
	\newcommand{\phonesym}{}
	\newcommand{\myphone}{}
	\newcommand{\email}{\texttt{rgiordan -at- mit.edu}}
\else
	\newcommand{\phonesym}{\phone}
	\newcommand{\myphone}{(805) 501-6754}
    \newcommand{\email}{\url{rgiordan@mit.edu}}
\fi

\newif\ifshowpaperrefs
\showpaperrefstrue

\ifshowpaperrefs
	\newcommand{\paperref}[1]{[\href{#1}{pdf}]}
\else
	\newcommand{\paperref}[1]{}
\fi

\begin{document}

\name{Ryan J. Giordano \vspace*{.1in}}

\begin{resume}
\section{\sc Contact Information}
\vspace{.05in}
\begin{tabular}{@{}p{2in}cp{4in}}
1515 Grant St.	& \Letter &\email  \\
Berkeley, CA, 94703	& \Mundus &\url{rgiordan.github.io} \\
USA		& \phonesym & \myphone \\
\end{tabular}

%\section{\sc Research Interests}
%%complexity of inference,
%large-scale learning,
%Bayesian inference,
%computational genomics.
%%inference algorithms for rich model classes (e.g., Bayesian nonparametric models, probabilistic program),
%%learning theory,
%%interface between learning and inference.


% \section{\sc Academic Experience}

% {\bf Boston University}, Boston, MA USA
% \begin{list1}
% \item[] {Assistant Professor, Department of Mathematics \& Statistics}  \hfill {2020--}
% \item[] {Founding Faculty of Computing \& Data Sciences} \hfill{2020--}
% \end{list1}
%
% {\bf Harvard University, Department of Biostatistics}, Boston, MA USA
% \begin{list1}
% \item[] {Postdoctoral Research Fellow.} Advisor: Jeffrey Miller  \hfill {2018--2019}
% \end{list1}
%{\bf Massachusetts Institute of Technology}, Cambridge, MA USA
%
%{\em Graduate Student} \hfill {\bf September 2012 - February 2018} \\
%{\em Department of EECS and Computer Science and Artificial Intelligence Laboratory}
%%Includes current Ph.D.~research, Ph.D.~and Masters level coursework and research/consulting projects.
%
%{\em Teaching Assistant} \hfill {\bf September 2016 - May 2017} \\
%Held office hours, conducted recitation sessions, graded homework,
%and advised students on class projects for graduate-level machine learning courses (6.862 and 6.867).

% {\bf Microsoft Research New England}, Cambridge, MA USA
% \begin{list1}
% \item[] {Research Intern.} Advisor: Lester Mackey \hfill {2017}
% \end{list1}


\section{\sc Education}

{{\bf Massachusetts Institute of Technology}, Cambridge, MA USA}
\begin{list1}
\item[] {\em Department of EECS, Computer Science \& Artificial Intelligence Lab}
\item[] {Postdoctoral Research Fellow.} Advisor: Tamara Broderick  \hfill {2019--present}
\end{list1}


{\bf University of California}, Berkeley, CA USA
\begin{list1}
%\item[] {\em Department of Statistics}
\item[] Ph.D., Statistics. Advisors: Michael I.~Jordan, Jon McAuliffe, Tamara Broderick \hfill {2013--2019}
\end{list1}


{\bf London School of Economics}, London, UK
\begin{list1}
%\item[] {\em Department of Economics}
\item[] MSc., Econometrics. \hfill {2007--2009}
\end{list1}

{\bf University of Illinois}, Urbana-Champaign, IL, USA
\begin{list1}
\item[] BA., Mathematics. \hfill {1997--2002}
\item[] BS., Theoretical and Applied Mechanics. \hfill {1997--2002}
\end{list1}


\section{\sc Professional Experience}

{\bf Google Inc.}, Mountain View, CA USA
\begin{list1}
\item[] Senior Engineer, Quantitiative Analysis \hfill {2009-2013}
\end{list1}

{\bf Macquarie Group}, London, UK
\begin{list1}
\item[] Risk Management Intern \hfill {2008}
\end{list1}

% {\bf LSE Financial Markets Group}, London, UK
% \begin{list1}
% \item[] Research Intern \hfill {2007}
% \end{list1}

{\bf United States Peace Corps}, Kokshetau, KZ
\begin{list1}
\item[] Education Volunteer, successful completion of service \hfill {2004-2006}
\end{list1}

{\bf Hewlett-Packard}, Boise, ID
\begin{list1}
\item[] Lifetest Coordinator and Reliability Engineer \hfill {2002-2004}
\end{list1}


\section{\sc Honors and Awards}

\begin{list1}

\item[] Notable Paper Award, Artificial Intelligence and Statistics (AISTATS) (2019)
\item[] Travel Award, Artificial Intelligence and Statistics (AISTATS) (2019)
\item[] Travel Award, Bayesian Nonparametrics Conference (2019)
\item[] Student Paper Award, ASA Section on Bayesian Statistical Science (2018)
\item[] Travel Award, International Society for Bayesian Analysis (ISBA) (2018)
\item[] Berkeley Institute for Data Science Fellow (2017-19)
\item[] Junior Travel Support Grant, International Society for Bayesian Analysis (ISBA) Bayes-Comp (2016)
\item[] Spotlight Paper, Neural Information Processing Systems (NeurIPS) (2015)
\item[] Outstanding Graduate Student Instructor Award (2015)
\item[] Travel Award, Neural Information Processing Systems Workshop on Variational Inference (2014)
\item[] Hertz Foundation Graduate Fellowship Finalist (2014)
\item[] Google Operating Committee Award (2010)
\item[] Advanced-high speaker of Russian in Peace Corps Aptitude Test (2006)
\item[] Advanced-mid speaker of Kazakh in Peace Corps Aptitude Test (2006)
\item[] Selected as a Peace Corps ``Success Story'' for a congressional report (2005)
\item[] Best Project, Undergraduate Mechanics Research Conference (2002)
\item[] Best Presentation, Undergraduate Mechanics Research Conference (2002)
\item[] Seely, Sinclair, Stippes, TAM Merit Scholarships (1998-2002)

\end{list1}


%{\bf Columbia University, Columbia College}, New York, NY USA
%
%{\em Undergraduate Researcher} \hfill {\bf June 2011 - May 2012} \\
%Conducted independent research in statistics for neuroscience (advisor: Liam Paninski)
%and Bayesian nonparametric modeling (advisor: Frank Wood).

%\vspace{-.1cm}
%{\em Teaching Assistant} \hfill {\bf June 2011 - May 2012} \\
%Duties included office hours and grading of homework for introductory statistics and data structures courses.

\section{\sc Preprints}

$\bullet$ T.~D.~Nguyen, \me, L.~Masoero, L.~Mackey \& \tamara (2020).
Independent finite approximations for Bayesian nonparametric inference: construction, error bounds, and practical implications.
\emph{arXiv:2009.10780 [stat.ME]}.
\paperref{https://arxiv.org/abs/2009.10780}


%\emph{Under review}.

\section{\sc Publications}

20. A.~K.~Dhaka, A.~Catalina, M.~R.~Andersen, M.~Magnusson, \me, A.~Vehtari (2020).
Robust, Accurate Stochastic Optimization for Variational Inference
In \emph{Proc. of the 34th Annual Conference on Neural Information Processing Systems (NeurIPS)}.
\paperref{https://arxiv.org/abs/2009.00666}

19. \me, M.~Kasprzak, \trevor \& \tamara (2020).
Practical posterior error bounds from variational objectives.
In \emph{Proc.~of the 22nd International Conference on Artificial Intelligence and Statistics (AISTATS)}.
\paperref{https://arxiv.org/abs/1910.04102}

$\star$ = contributed equally

\section{\sc Workshop \\ Papers}

3. B.~Trippe, \me \& \tamara (2018).
Fast Bayesian Inference in GLMs with Low Rank Data Approximations.
In \emph{Symposium on Advances in Approximate Bayesian Inference}.

2. \me, L.~Masoero, L.~Mackey \& \tamara (2017).
Generic finite approximations for practical Bayesian nonparametrics.
In \emph{NeurIPS 2017 Workshop on Advances in Approximate Bayesian Inference}.

%\section{\sc Conference Presentations}

\section{\sc Miscellanea}

3. \me, M.~Kasprzak, \trevor \& \tamara (2018).
Practical bounds on the error of Bayesian posterior approximations: A nonasymptotic approach.
\emph{arXiv:1809.09505 [stat.TH]}.
\paperref{https://arxiv.org/abs/1809.09505}

2. \me, A.~Saeedi \& M.~J.~Johnson (2014).
Detailed Derivations of Small-variance Asymptotics for some Hierarchical Bayesian Nonparametric Models.
\emph{arXiv:1501.00052 [stat.ML]}.
\paperref{http://arxiv.org/abs/1501.00052}

1. \me \& F.~Wood (2014).
Infinite structured hidden semi-Markov models.
\emph{arXiv:1407.0044 [stat.ME]}.
\paperref{http://arxiv.org/abs/1407.0044}



\section{\sc Invited Talks}

\textbf{Previous}

\emph{Using Bagged Posteriors for Robust Inference}

\begin{talkgroup}
Northeastern University, Boston, MA \hfill February 2020 \\
SPIRAL Seminar Series

Oxford University, Oxford, UK \hfill October 2019 \\
Statistics Seminar

Bristol University, Bristol, UK \hfill October 2019 \\
Data Science Seminar \\
Statistics Seminar

Massachusetts Institute of Technology, Cambridge, MA  \hfill November 2019 \\
Doctoral Seminar in Statistics

Broad Institute of MIT and Harvard, Cambridge, MA \hfill December 2019 \\
Models, Inference, and Algorithms

\end{talkgroup}

\emph{Scalable, Reliably Accurate Bayesian Inference via Approximate Likelihoods and Random Features}

\begin{talkgroup}
Google AI, Cambridge, MA \hfill February 2019

Broad Institute of MIT and Harvard, Cambridge, MA \hfill February 2019
% Department of Electrical and Computer Engineering,

Northeastern University, Boston, MA \hfill February 2019

%\emph{Scalable, Reliably Accurate Bayesian Inference via Approximate Likelihoods and Random Features}
%Department of Mathematics \& Statistics,
Boston University, Boston, MA \hfill January 2019

\end{talkgroup}

\emph{Finite-dimensional Approximations of Completely Random Measures}

\begin{talkgroup}
Stochastic Processes and Applications (SPA), Gothenburg, Sweden \hfill June 2018

\end{talkgroup}


\emph{Scaling Bayesian Inference by Constructing Approximating Exponential Families}

\begin{talkgroup}
Boston Bayesian Meetup, Boston, MA \hfill April 2018

Schlumberger Doll Research, Cambridge, MA \hfill April 2018

Raytheon BBN Technologies, Cambridge, MA \hfill February 2018

\end{talkgroup}



\section{\sc Contributed Talks}

%\textbf{Upcoming} \\[-.5em]
%
%\begin{talkgroup}
%
%Bernoulli--IMS One World Symposium \hfill August 2020
%
%\end{talkgroup}



\textbf{Previous}

\emph{Using Bagged Posteriors for Robust Inference}
\begin{talkgroup}
Bayes Comp, Gainesville, FL \hfill January 2020
\end{talkgroup}

\emph{Robustness and scalability of Bayesian nonnegative matrix factorization}
\begin{talkgroup}
Joint Statistical Meeting (JSM), Denver, CO \hfill July 2019
\end{talkgroup}

\emph{Scaling Bayesian Inference by Constructing Approximating Exponential Families}
\begin{talkgroup}
ISBA World Meeting, Edinburgh, Scotland \hfill June 2018
\end{talkgroup}

\emph{Truncated Random Measures}
\begin{talkgroup}
11th Conference on Bayesian Nonparametrics (BNP11), Paris, France \hfill June 2017
\end{talkgroup}

\section{\sc Professional Service}

\textbf{Journal Reviewing}
\begin{list2}
\item Journal of Machine Learning Research
\end{list2}

\textbf{Conference Reviewing}
\begin{list2}
\item Advances in Neural Information Processing Systems (NeurIPS)
\item International Conference on Machine Learning (ICML)
\item International Conference on Artificial Intelligence and Statistics (AISTATS)
\end{list2}


\section{\sc Teaching}

\emph{University of California, Berkeley, USA}
\begin{list2}
\item Teaching Assistant, STAT215 Applied Statistics
(Graduate-level) \hfill Fall 2014
\end{list2}

\emph{Kokshetau Elementary School \#3, Kokshetau, Kazakhstan}
\begin{list2}
\item Elementary school teacher of mathematics and English as a second language
\hfill 2004-2006
\end{list2}

\emph{University of Illinois, Urbana-Champaign, USA}
\begin{list2}
\item Teaching Assistant, Mechanics of Materials Lab \hfill Fall 1999
\item Teaching Assistant, Introduction to Statics \hfill Spring 1999
\end{list2}



%Worked with multiple teams on natural language processing problems such as
%co-reference finding, action recognition in free text, and named entity recognition.
%Projects were implemented in OCaml, Python, and Perl and used techniques such as
%integer linear programming and conditional random fields.


%\section{\sc Computer Skills}
%\begin{list2}
%\item Languages: C++, Java, Python, Perl, Matlab, and OCaml
%\item Algorithms: Markov chain Monte Carlo techniques for Bayesian posterior inference
%\end{list2}

\end{resume}
\end{document}
