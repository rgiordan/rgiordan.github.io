I"a<p>In the previous post, I introduced some notation and concepts that I’ll
now carry forward into an actual sketch of how to prove the BCLT.</p>

<h1 id="re-write-a-posterior-expectation-as-a-random-function-that-doesnt-diverge">Re-write a posterior expectation as a random function that doesn’t diverge.</h1>

<p>Recall that, for the BCLT we need to analyze quantites of the following form:</p>

\[\mathbb{E}[\phi(\theta) | x] =
\frac{\int \phi(\theta) \exp(\sum_{n=1}^N \ell(x_n | \theta)) \pi(\theta) d\theta}
     {\int \exp(\sum_{n=1}^N \ell(x_n | \theta)) \pi(\theta) d\theta}.\]

<p>And recall that, to prove asymptotic normality of the MLE, we studied
the asymptotic behavior of the Taylor expansion of the
random log likelihood function,</p>

\[\theta \mapsto \frac{1}{N} \sum_{n=1}^N \ell(x_n \vert \theta).\]

<p>The factor of \(1/N\) in the MLE is a stark difference with the Bayesian
case, as the posterior involves the random function</p>

\[\theta \mapsto \sum_{n=1}^N \ell(x_n | \theta),\]

<p>which diverges as \(N \rightarrow \infty\)!  Before even beginning, we must
re-write our expectation in a form involving something that looks like sample
averages, not a divergent sum.</p>

<p>To do so, we’ll first form a Taylor series expansion.  For the moment, we’ll
expand around a generic \(\bar\theta\).</p>

\[\sum_{n=1}^N \ell(x_n | \theta) =
    \sum_{n=1}^N \ell(x_n | \bar\theta) +
    \sum_{n=1}^N \ell_{(1)}(x_n | \bar\theta)(\theta - \bar\theta) +
    \frac{1}{2}\sum_{n=1}^N \ell_{(2)}(x_n | \bar\theta)(\theta - \bar\theta)^2 +
    \frac{1}{6}\sum_{n=1}^N \ell_{(3)}(x_n | \tilde\theta)(\theta - \bar\theta)^3.\]

<p>At first glance, each term in the Taylor series still contains \(N\) terms,
so it might not seem like we’ve gotten much.  However, we expect to be
able to choose \(\bar\theta\) so that \(|\theta - \bar\theta| = O(1 / \sqrt{N})\),
so that higher powers of \(\theta - \bar\theta\) will decrease asymptotically.</p>

<p>So let’s try a parameterization that inflates \(\theta\) at the rate
\(\sqrt{N}\).  Specifically, for any \(\bar\theta\) depending only on the data,
we can define the Bayesian parameter</p>

\[\tau := \sqrt{N} (\theta - \bar\theta)
\quad\quad \Leftrightarrow \quad \quad
\theta = \frac{\tau}{\sqrt{N}} + \bar\theta.\]

<p>Plugging in, we have</p>

\[\sum_{n=1}^N \ell(x_n | \theta) =
    \sum_{n=1}^N \ell(x_n | \bar\theta) +
    \frac{1}{\sqrt{N}} \sum_{n=1}^N \ell_{(1)}(x_n | \bar\theta) \tau +
    \frac{1}{2} \frac{1}{N} \sum_{n=1}^N \ell_{(2)}(x_n | \bar\theta)\tau^2 +
    \frac{1}{6} \frac{1}{N^{3/2}} \sum_{n=1}^N \ell_{(3)}(x_n | \tilde\theta)\tau^3.\]

<p>Note that in this new formula, the derivatives are still with respect to
\(\theta\) — we’ve simply plugged \(\tau\) into the previous expression.</p>

<p>Now we’re getting somewhere, because the quadratic term looks like what we
expect from a normal distribution, and the cubic term is a sample average
times an additional power of \(1/\sqrt{N}\), and so goes to zero.</p>

<p>Two terms need to be dealt with.  First, However, the term \(\frac{1}{\sqrt{N}}
\sum_{n=1}^N \ell_{(1)}(x_n | \bar\theta) \tau\) is \(O_p(1)\) by an ordinary
central limit theorem.  Fortunately, we can get rid of this term by simply
evaluating at \(\bar\theta = \hat\theta\), since then \(\sum_{n=1}^N
\ell_{(1)}(x_n | \bar\theta)\) is identically zero by the first-order condition
defining \(\hat\theta\). And, second, we observe that \(\sum_{n=1}^N \ell(x_n |
\bar\theta)\) does not depend on \(\theta\), and so cancels in the numerator and
denominator of \(\mathbb{E}[\phi(\theta) | x]\).</p>

<p>Before we plug into \(\mathbb{E}[\phi(\theta) | x]\), we need to deal with
the effect of the change of variables on the prior.  By the ordinary rules
of density transformation, \(\pi(\theta) d\theta\) = \(\pi(\sqrt{N} \tau + \hat\theta)\).
Putting this together, and using the fact that \(p(\tau) = \pi(\theta)\) we get</p>

\[\mathbb{E}[\phi(\theta) | x] =
\frac{\int \phi(\theta) \exp\left(
    \frac{1}{2} \frac{1}{N} \sum_{n=1}^N \ell_{(2)}(x_n | \hat\theta)\tau^2 +
    \frac{1}{6} \frac{1}{N^{3/2}} \sum_{n=1}^N \ell_{(3)}(x_n | \tilde\theta)\tau^3
\right)
    \pi(\theta) d\theta}
 {\int \exp\left(
     \frac{1}{2} \frac{1}{N} \sum_{n=1}^N \ell_{(2)}(x_n | \hat\theta)\tau^2 +
     \frac{1}{6} \frac{1}{N^{3/2}} \sum_{n=1}^N \ell_{(3)}(x_n | \tilde\theta)\tau^3
  \right)\pi(\theta) d\theta}.\]

<p>Now, to express</p>
:ET